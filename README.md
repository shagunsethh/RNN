# Sentiment Analysis Using RNN

# Group 27
#### Shagun Seth(055042)
#### Sweta Behera(055051)

## ğŸ“Œ Problem Statement
Customer reviews on e-commerce platforms like Amazon contain valuable insights about user experiences. However, manually analyzing thousands of reviews is impractical. This project automates sentiment analysis using *recurrent neural networks (RNNs)* to classify reviews as positive or negative.

## ğŸ“– Abstract
This study implements a *LSTM-based RNN* for sentiment analysis. It preprocesses Amazon reviews by *removing stopwords, tokenizing text, and applying word embeddings (GloVe)*. The model is trained on a balanced dataset and evaluated using multiple performance metrics.

*Final Model Accuracy: 96.37%* ğŸ¯

---

## ğŸ“Š Dataset Description
â€¢â   â *Source:* Amazon Reviews Dataset  
â€¢â   â *Features:*  
  - â â€¯Review Textâ€¯â : Customer feedback  
  - â â€¯Sentiment Labelâ€¯â : 0 = Negative, 1 = Positive  
â€¢â   â *Preprocessing Applied:*  
  - Removed stopwords while retaining key sentiment words (e.g., "not")  
  - Converted text to numerical sequences using *GloVe embeddings*  

---

## ğŸš€ Steps Performed

### ğŸ”¹ Data Preprocessing
âœ” Cleaned and tokenized text  
âœ” Applied padding for uniform input lengths  

### ğŸ”¹ Exploratory Data Analysis (EDA)
âœ” *Visualized sentiment distribution*  
âœ” Created *word clouds* for frequent words in positive & negative reviews  

### ğŸ”¹ Handling Class Imbalance
âœ” Applied *SMOTE* to oversample minority class  

### ğŸ”¹ Feature Engineering
âœ” Used *GloVe word embeddings* instead of TF-IDF  

### ğŸ”¹ Model Training & Evaluation
âœ” Implemented a *Bidirectional LSTM-based RNN*  
âœ” Used *dropout and batch normalization*  
âœ” *Fine-tuned hyperparameters* for best results  
âœ” Evaluated performance using *accuracy, confusion matrix, and F1-score*  

---

## ğŸ“ˆ Model Performance

### âœ… *Final Accuracy: 96.37%*
â€¢â   â *Training Loss:* 0.1198  
â€¢â   â *Validation Loss:* 0.1765  

### âœ… *Confusion Matrix*
| Sentiment | Precision | Recall | F1-score | Support |
|-----------|-----------|---------|-----------|---------|
| Negative  | 0.94      | 0.99    | 0.96      | 579     |
| Positive  | 0.99      | 0.93    | 0.96      | 579     |
| *Overall* | *0.97* | *0.96* | *0.96* | *1158* |

ğŸ“Š *Misclassification Analysis:*  
â€¢â   â Some reviews had *mixed sentiment*, leading to incorrect predictions.  
â€¢â   â Short reviews were harder to classify due to lack of context.  

---

## ğŸ” Key Insights
âœ” *GloVe embeddings enhanced performance* over TF-IDF  
âœ” *Class balancing (SMOTE) improved model fairness*  
âœ” *Bidirectional LSTM captured long-range dependencies effectively*  
âœ” *Dropout layers reduced overfitting*  

---

## ğŸ¯ Managerial Implications
ğŸ“Œ *Customer Experience Insights:* Identify areas for product improvement  
ğŸ“Œ *Brand Reputation Management:* Real-time monitoring of customer sentiment  
ğŸ“Œ *Competitive Intelligence:* Compare sentiment trends across competitors  
ğŸ“Œ *Automated Review Moderation:* Filter spam or inappropriate content  

---

## ğŸ”® Future Enhancements
ğŸš€ Implement *BERT/GPT models* for better context understanding  
ğŸš€ Expand to *multi-language sentiment analysis*  
ğŸš€ Introduce *sentiment scoring* instead of binary classification  
ğŸš€ Deploy as an *API for real-time sentiment tracking*  

---

## ğŸ›  Technical Stack
â€¢â   â *Deep Learning:* TensorFlow, Keras, PyTorch  
â€¢â   â *NLP Libraries:* NLTK, Spacy, Gensim  
â€¢â   â *Visualization:* Matplotlib, Seaborn  
â€¢â   â *Data Processing:* Pandas, NumPy, Scikit-learn  

---

## ğŸ“š References
â€¢â   â Amazon Reviews Dataset  
â€¢â   â Research Papers on LSTM & Sentiment Analysis  

---

## â­ Final Thoughts
This project demonstrates the power of *deep learning for sentiment analysis. With **96.37% accuracy, it provides a robust tool for extracting insights from customer feedback. Future improvements, such as **BERT models and real-time sentiment tracking*, will further enhance its applications in business intelligence.
